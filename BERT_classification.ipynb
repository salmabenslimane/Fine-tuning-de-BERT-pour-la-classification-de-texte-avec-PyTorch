{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72c6ea2b",
   "metadata": {},
   "source": [
    "    The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01464854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"glue\", \"sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45a8b4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': 'hide new secretions from the parental units ', 'label': 0, 'idx': 0}\n",
      "{'sentence': Value('string'), 'label': ClassLabel(names=['negative', 'positive']), 'idx': Value('int32')}\n",
      "(67349, 3)\n",
      "{'sentence': ['hide new secretions from the parental units ', 'contains no wit , only labored gags ', 'that loves its characters and communicates something rather beautiful about human nature ', 'remains utterly satisfied to remain the same throughout ', 'on the worst revenge-of-the-nerds clichés the filmmakers could dredge up '], 'label': [0, 0, 1, 0, 0], 'idx': [0, 1, 2, 3, 4]}\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0])\n",
    "print(dataset['train'].features)\n",
    "print(dataset['train'].shape)\n",
    "print(dataset['train'][0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de712cb",
   "metadata": {},
   "source": [
    "Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9472e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"sentence\"], padding=True, truncation=True)\n",
    "\n",
    "dataset_encoded = dataset.map(tokenize, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b06e4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': Value('string'), 'label': ClassLabel(names=['negative', 'positive']), 'idx': Value('int32'), 'input_ids': List(Value('int32')), 'token_type_ids': List(Value('int8')), 'attention_mask': List(Value('int8'))}\n",
      "(67349, 6)\n",
      "{'sentence': ['hide new secretions from the parental units '], 'label': [0], 'idx': [0], 'input_ids': [[101, 5342, 2047, 3595, 8496, 2013, 1996, 18643, 3197, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
     ]
    }
   ],
   "source": [
    "print(dataset_encoded[\"train\"].features)\n",
    "print(dataset_encoded[\"train\"].shape)\n",
    "print(dataset_encoded[\"train\"][0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da52b822",
   "metadata": {},
   "source": [
    "Transformer le dataset en Tensor: Le modèle n’a pas besoin de la phrase texte ni de l’index — il apprend uniquement à relier input_ids → label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "776b43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_encoded.set_format(\n",
    "    type='torch',\n",
    "    columns=['input_ids', 'attention_mask', 'label']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c933f7",
   "metadata": {},
   "source": [
    "Le DataLoader est un outil PyTorch qui :\n",
    "\n",
    "- Découpe ton dataset en petits lots (batches),\n",
    "\n",
    "- Mélange les exemples pour éviter que le modèle apprenne par ordre fixe,\n",
    "\n",
    "- Envoie automatiquement les données à chaque étape de ton entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0050edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(dataset_encoded[\"train\"], batch_size=16, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
